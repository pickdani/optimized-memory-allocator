Hw vec   |  10,000 – 7.308s
opt vec  |  100,000 – 0.678s
sys vec  |  1,000,000 – 8.355s
hw list  |  10,000 – 0.674s
opt list |  100,000 – 2.055s
sys list |  100,000 – 3.206s

input size = 10000
opt vec  |   0.086s
hw vec   |   7.308s
opt faster by 7.222s

input size = 30000
opt list |   0.545s
hw list  |   10.624s
opt faster by 10.079s

input size = 500000
opt vec  |  3.687s
sys vec  |  4.950s
opt faster by 1.263s

input size = 300000
opt list |  7.655s
sys list |  11.185s 
opt faster by 3.530s

Optimizing the allocator
- We used bucket allocator as shown in the lecture with buckets of size n^2 to get a constant time for free and malloc. Our bucket goes up to size 4096. large allocations directly mmap and munmap. We utilized _thread to allow each thread to have its own set of buckets while running in parallel.

Challenge
- finding the right techniques which were not too difficult to implement while also providing a significant speedup. We tried to implement doubly linked lists, which was difficult and did not speed up our code.

Reuse
- when something is free it is added to the front of the list corresponding to closest power of 2 size bucket that is is in. This can be used later on by our malloc call.

Redo
 - yes, because it was able to provide a noticeable speedup while being easy to understand and implement compared to other techniques.
